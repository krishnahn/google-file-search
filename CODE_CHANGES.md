# Code Changes: Performance Optimization

## Summary of Changes

**File Modified:** `/Users/macbookpro16_stic_admin/Documents/google_file_search/src/search_manager.py`

**Changes Made:**
1. Added file object caching infrastructure
2. Created cached file retrieval method
3. Added cache management utilities
4. Updated search methods to use caching

---

## Detailed Code Changes

### Change 1: Added Cache Infrastructure (Lines 31-34)

**Location:** `__init__` method of `SearchManager` class

```python
# ADDED - Performance optimization cache
self._file_cache: Dict[str, Any] = {}
self._cache_ttl = 3600  # Cache files for 1 hour
self._cache_timestamps: Dict[str, float] = {}
```

**Purpose:**
- `_file_cache`: Stores file objects keyed by file name
- `_cache_ttl`: Time-to-live for cached objects (1 hour = 3600 seconds)
- `_cache_timestamps`: Tracks when each file was cached for expiration logic

---

### Change 2: Created Cached File Retrieval Method (Lines 36-58)

**Location:** New method in `SearchManager` class

```python
def _get_file_cached(self, file_name: str) -> Any:
    """
    Get file object with caching to avoid repeated API calls.

    Args:
        file_name: Name of the file to retrieve

    Returns:
        File object from cache or API
    """
    current_time = time.time()

    # Check if file is in cache and not expired
    if file_name in self._file_cache:
        cache_age = current_time - self._cache_timestamps.get(file_name, 0)
        if cache_age < self._cache_ttl:
            return self._file_cache[file_name]

    # Fetch from API and cache
    file_obj = genai.get_file(file_name)
    self._file_cache[file_name] = file_obj
    self._cache_timestamps[file_name] = current_time
    return file_obj
```

**Logic Flow:**
1. Get current timestamp
2. Check if file exists in cache
3. If cached, check if cache is still valid (not expired)
4. If valid, return cached object (fast path)
5. If not in cache or expired, fetch from API
6. Store in cache with current timestamp
7. Return file object

**Performance Impact:**
- Cache hit (warm cache): ~0ms (instant memory retrieval)
- Cache miss (cold cache): ~200ms (API call + cache storage)

---

### Change 3: Added Cache Management Method (Lines 60-64)

**Location:** New method in `SearchManager` class

```python
def clear_cache(self):
    """Clear the file object cache."""
    self._file_cache.clear()
    self._cache_timestamps.clear()
    print("‚úÖ File cache cleared")
```

**Purpose:**
- Allows manual cache clearing when needed
- Useful for testing or troubleshooting
- Ensures clean state when required

**Usage:**
```python
search_manager = SearchManager(client)
search_manager.clear_cache()  # Force fresh API calls
```

---

### Change 4: Updated search_and_generate Method (Line 119)

**Location:** `search_and_generate` method

**BEFORE:**
```python
# Prepare content with files
content = [formatted_query]
for file_name in file_names:
    try:
        file_obj = genai.get_file(file_name)  # ‚ö†Ô∏è Always hits API
        content.append(file_obj)
    except Exception as e:
        print(f"‚ö†Ô∏è  Could not access file {file_name}: {e}")
```

**AFTER:**
```python
# Prepare content with files (using cache for performance)
content = [formatted_query]
for file_name in file_names:
    try:
        file_obj = self._get_file_cached(file_name)  # ‚úÖ Uses cache
        content.append(file_obj)
    except Exception as e:
        print(f"‚ö†Ô∏è  Could not access file {file_name}: {e}")
```

**Change:**
- `genai.get_file(file_name)` ‚Üí `self._get_file_cached(file_name)`
- Comment updated to reflect caching

---

### Change 5: Updated search_multiple_stores Method (Line 195)

**Location:** `search_multiple_stores` method

**BEFORE:**
```python
content = [formatted_query]
for file_name in all_files:
    try:
        file_obj = genai.get_file(file_name)  # ‚ö†Ô∏è Always hits API
        content.append(file_obj)
    except Exception as e:
        print(f"‚ö†Ô∏è  Could not access file {file_name}: {e}")
```

**AFTER:**
```python
content = [formatted_query]
for file_name in all_files:
    try:
        file_obj = self._get_file_cached(file_name)  # ‚úÖ Uses cache
        content.append(file_obj)
    except Exception as e:
        print(f"‚ö†Ô∏è  Could not access file {file_name}: {e}")
```

**Change:**
- `genai.get_file(file_name)` ‚Üí `self._get_file_cached(file_name)`

---

## Complete Modified Code Sections

### Section 1: Class Initialization

```python
class SearchManager:
    """Manages search operations and query processing with Google AI files."""

    def __init__(self, client: FileSearchClient, model_name: Optional[str] = None):
        """
        Initialize SearchManager.

        Args:
            client: FileSearchClient instance
            model_name: Model to use for generation (defaults to settings)
        """
        self.client = client
        self.model_name = model_name or settings.default_model
        self.response_handler = ResponseHandler()

        # Configure the generative AI client
        genai.configure(api_key=self.client.api_key)

        # Performance optimization: Cache file objects to avoid repeated API calls
        self._file_cache: Dict[str, Any] = {}
        self._cache_ttl = 3600  # Cache files for 1 hour
        self._cache_timestamps: Dict[str, float] = {}
```

### Section 2: Cache Methods

```python
    def _get_file_cached(self, file_name: str) -> Any:
        """
        Get file object with caching to avoid repeated API calls.

        Args:
            file_name: Name of the file to retrieve

        Returns:
            File object from cache or API
        """
        current_time = time.time()

        # Check if file is in cache and not expired
        if file_name in self._file_cache:
            cache_age = current_time - self._cache_timestamps.get(file_name, 0)
            if cache_age < self._cache_ttl:
                return self._file_cache[file_name]

        # Fetch from API and cache
        file_obj = genai.get_file(file_name)
        self._file_cache[file_name] = file_obj
        self._cache_timestamps[file_name] = current_time
        return file_obj

    def clear_cache(self):
        """Clear the file object cache."""
        self._file_cache.clear()
        self._cache_timestamps.clear()
        print("‚úÖ File cache cleared")
```

### Section 3: Updated Search Method

```python
    def search_and_generate(
        self,
        query: str,
        store_name: str,
        system_prompt: Optional[str] = None,
        temperature: float = 0.1,
        max_tokens: Optional[int] = None
    ) -> SearchResponse:
        """
        Perform semantic search and generate response using uploaded files.

        Args:
            query: User query
            store_name: File store to search
            system_prompt: Optional system prompt override
            temperature: Generation temperature (0.0-1.0)
            max_tokens: Maximum tokens in response

        Returns:
            SearchResponse with answer and citations
        """
        try:
            # Get files from the store
            file_names = self.client.get_files_for_generation(store_name)
            if not file_names:
                return SearchResponse(
                    answer=f"No files found in store '{store_name}'. Please upload some documents first.",
                    citations=[],
                    model_used=self.model_name,
                    query=query
                )

            # Prepare the prompt
            formatted_query = PromptTemplates.format_search_prompt(query)

            print(f"üîç Searching {len(file_names)} files in store '{store_name}' for: {query[:100]}...")

            # Create model instance
            generation_config = genai.GenerationConfig(
                temperature=temperature,
                max_output_tokens=max_tokens
            )

            model = genai.GenerativeModel(
                model_name=self.model_name,
                generation_config=generation_config,
                system_instruction=system_prompt or PromptTemplates.RAG_SYSTEM_PROMPT
            )

            # Prepare content with files (using cache for performance)
            content = [formatted_query]
            for file_name in file_names:
                try:
                    file_obj = self._get_file_cached(file_name)  # ‚úÖ OPTIMIZED
                    content.append(file_obj)
                except Exception as e:
                    print(f"‚ö†Ô∏è  Could not access file {file_name}: {e}")

            # Generate response with file context
            response = model.generate_content(content)

            # Process the response
            search_response = self.response_handler.process_response(
                response=response,
                query=query,
                model_name=self.model_name
            )

            print(f"‚úÖ Generated response from {len(file_names)} files")
            return search_response

        except Exception as e:
            print(f"‚ùå Error during search and generation: {e}")
            # Return error response
            return SearchResponse(
                answer=f"Error processing query: {e}",
                citations=[],
                model_used=self.model_name,
                query=query
            )
```

---

## Configuration Options

### Adjust Cache TTL

To change how long files are cached, modify the `_cache_ttl` value in `__init__`:

```python
# Default: 1 hour (3600 seconds)
self._cache_ttl = 3600

# Examples:
self._cache_ttl = 1800   # 30 minutes
self._cache_ttl = 7200   # 2 hours
self._cache_ttl = 300    # 5 minutes
self._cache_ttl = 86400  # 24 hours
```

**Considerations:**
- Longer TTL = Better performance, but risk of stale data
- Shorter TTL = Fresher data, but more API calls
- Google's files expire after 48 hours anyway
- Recommended: 1-2 hours for most use cases

### Manual Cache Control

```python
# Clear cache manually
search_manager.clear_cache()

# Check cache contents (for debugging)
print(f"Cached files: {list(search_manager._file_cache.keys())}")
print(f"Cache size: {len(search_manager._file_cache)} files")
```

---

## Testing the Changes

### Quick Test

```python
from src.file_search_client import FileSearchClient
from src.search_manager import SearchManager
import time

client = FileSearchClient()
search_manager = SearchManager(client)

# First query (cold cache)
start = time.time()
response1 = search_manager.search_and_generate(
    "What are the requirements?",
    "nursing-knowledge"
)
cold_time = time.time() - start
print(f"Cold cache: {cold_time:.2f}s")

# Second query (warm cache)
start = time.time()
response2 = search_manager.search_and_generate(
    "What about eligibility?",
    "nursing-knowledge"
)
warm_time = time.time() - start
print(f"Warm cache: {warm_time:.2f}s")

print(f"Improvement: {((cold_time - warm_time) / cold_time * 100):.1f}%")
```

### Comprehensive Test

```bash
python test_performance.py
```

---

## Backward Compatibility

**Good News:** These changes are 100% backward compatible!

- No changes to public API
- No changes to method signatures
- No changes to return types
- Existing code continues to work unchanged
- Only internal implementation optimized

**Example - No code changes needed:**
```python
# This code works exactly the same before and after optimization
search_manager = SearchManager(client)
response = search_manager.search_and_generate("query", "store")
print(response.answer)
```

---

## Performance Metrics

### Expected Improvements

| Metric | Before | After (Warm Cache) | Improvement |
|--------|--------|-------------------|-------------|
| File Retrieval Time | 2-4 seconds | <0.1 seconds | 95-98% |
| Total Query Time | 3-5 seconds | 1-2 seconds | 40-60% |
| API Calls (10 files) | 10 calls | 0 calls | 100% |
| User Wait Time | Long | Short | Significant |

### Cache Statistics

For a typical session with 10 files and 20 queries:

**Without Cache:**
- API calls: 200 (10 files √ó 20 queries)
- Network overhead: ~40 seconds
- Rate limit pressure: High

**With Cache:**
- API calls: 10 (first query only)
- Network overhead: ~2 seconds
- Rate limit pressure: Low
- **Improvement: 95% reduction**

---

## Rollback Instructions

If you need to revert these changes:

1. **Remove cache initialization** (delete lines 31-34)
2. **Remove cache methods** (delete lines 36-64)
3. **Restore original API calls:**
   - Line 119: `self._get_file_cached(file_name)` ‚Üí `genai.get_file(file_name)`
   - Line 195: `self._get_file_cached(file_name)` ‚Üí `genai.get_file(file_name)`

Or simply restore from the old version:
```bash
cp src/search_manager_old.py src/search_manager.py
```

---

## Files Modified

1. `/Users/macbookpro16_stic_admin/Documents/google_file_search/src/search_manager.py`

## Files Created

1. `/Users/macbookpro16_stic_admin/Documents/google_file_search/test_performance.py`
2. `/Users/macbookpro16_stic_admin/Documents/google_file_search/OPTIMIZATION_REPORT.md`
3. `/Users/macbookpro16_stic_admin/Documents/google_file_search/QUICK_SUMMARY.md`
4. `/Users/macbookpro16_stic_admin/Documents/google_file_search/PERFORMANCE_VISUALIZATION.md`
5. `/Users/macbookpro16_stic_admin/Documents/google_file_search/CODE_CHANGES.md` (this file)

---

**Last Updated:** November 28, 2025
**Version:** 1.0 (Optimized)
