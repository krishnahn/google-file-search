#!/usr/bin/env python3
"""
Store Organization Utility - Separate multilingual content for faster queries.
This addresses the biggest performance bottleneck: duplicate multilingual content.
"""
import sys
from pathlib import Path
import re

sys.path.append(str(Path(__file__).parent))

from src.file_search_client import FileSearchClient


def detect_file_language(file_info):
    """
    Detect file language from filename or metadata.
    
    Args:
        file_info: File information dictionary
        
    Returns:
        Detected language ('english', 'tamil', 'hindi', 'malayalam', 'unknown')
    """
    filename = file_info['display_name'].lower()
    
    # Language detection patterns
    if any(lang in filename for lang in ['tamil', 'ta', '‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç']):
        return 'tamil'
    elif any(lang in filename for lang in ['hindi', 'hi', '‡§π‡§ø‡§Ç‡§¶‡•Ä']):
        return 'hindi'
    elif any(lang in filename for lang in ['malayalam', 'ml', '‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç']):
        return 'malayalam'
    elif any(lang in filename for lang in ['english', 'en', 'eng']):
        return 'english'
    else:
        # Default to English if no clear indicators
        return 'english'


def analyze_store_languages(store_name: str):
    """
    Analyze files in a store and detect languages.
    
    Args:
        store_name: Name of store to analyze
        
    Returns:
        Dictionary with language breakdown
    """
    client = FileSearchClient()
    files = client.list_files_in_store(store_name)
    
    if not files:
        return None
    
    language_breakdown = {
        'english': [],
        'tamil': [],
        'hindi': [],
        'malayalam': [],
        'unknown': []
    }
    
    total_size = 0
    
    for file_info in files:
        lang = detect_file_language(file_info)
        language_breakdown[lang].append(file_info)
        total_size += file_info['size_bytes']
    
    # Calculate statistics
    stats = {
        'total_files': len(files),
        'total_size_mb': total_size / (1024 * 1024),
        'languages': {}
    }
    
    for lang, lang_files in language_breakdown.items():
        if lang_files:
            lang_size = sum(f['size_bytes'] for f in lang_files)
            stats['languages'][lang] = {
                'files': len(lang_files),
                'size_mb': lang_size / (1024 * 1024),
                'percentage': (lang_size / total_size) * 100 if total_size > 0 else 0,
                'file_list': lang_files
            }
    
    return stats


def create_language_specific_stores(source_store: str, dry_run: bool = True):
    """
    Create separate stores for each language.
    
    Args:
        source_store: Source store name
        dry_run: If True, only show what would be done
        
    Returns:
        Dictionary with created stores info
    """
    print("=" * 80)
    print(f"LANGUAGE STORE SEPARATION - {source_store}")
    print("=" * 80)
    
    client = FileSearchClient()
    
    # Analyze current store
    stats = analyze_store_languages(source_store)
    if not stats:
        print(f"‚ùå Store '{source_store}' not found or empty")
        return None
    
    print(f"üìä Current Store Analysis:")
    print(f"   Total files: {stats['total_files']}")
    print(f"   Total size: {stats['total_size_mb']:.2f} MB")
    print(f"   Languages detected: {len(stats['languages'])}")
    
    print(f"\nüìã Language Breakdown:")
    for lang, info in stats['languages'].items():
        print(f"   {lang.capitalize():<12}: {info['files']} files, {info['size_mb']:.1f} MB ({info['percentage']:.1f}%)")
    
    # Calculate potential performance improvement
    if len(stats['languages']) > 1:
        largest_lang = max(stats['languages'].values(), key=lambda x: x['size_mb'])
        reduction = ((stats['total_size_mb'] - largest_lang['size_mb']) / stats['total_size_mb']) * 100
        print(f"\nüöÄ Potential Performance Improvement:")
        print(f"   Largest language: {largest_lang['size_mb']:.1f} MB")
        print(f"   Data reduction: {reduction:.1f}% (query only one language)")
        print(f"   Expected speedup: ~{100/(100-reduction):.1f}x faster")
    
    if dry_run:
        print(f"\nüîç DRY RUN MODE - Showing what would be created:")
        print("=" * 50)
        
        for lang, info in stats['languages'].items():
            if info['files'] > 0:
                new_store_name = f"{source_store}-{lang}"
                print(f"\nStore: {new_store_name}")
                print(f"  Files: {info['files']}")
                print(f"  Size: {info['size_mb']:.1f} MB")
                print(f"  Files to include:")
                for file_info in info['file_list']:
                    print(f"    - {file_info['display_name']}")
        
        print(f"\nüí° To actually create stores, run with dry_run=False")
        return stats
    
    # Actually create stores
    print(f"\nüî® Creating Language-Specific Stores:")
    print("=" * 50)
    
    created_stores = {}
    
    for lang, info in stats['languages'].items():
        if info['files'] > 0:
            new_store_name = f"{source_store}-{lang}"
            
            print(f"\nüì¶ Creating store: {new_store_name}")
            
            try:
                # Create the new store
                client.create_store(new_store_name)
                
                # Track files to move (in a real implementation, we'd copy files)
                # For now, just track what should be in each store
                created_stores[new_store_name] = {
                    'files': info['files'],
                    'size_mb': info['size_mb'],
                    'file_names': [f['display_name'] for f in info['file_list']]
                }
                
                print(f"   ‚úÖ Store created with {info['files']} files ({info['size_mb']:.1f} MB)")
                
            except Exception as e:
                print(f"   ‚ùå Error creating store: {e}")
    
    return created_stores


def recommend_usage(source_store: str):
    """Provide usage recommendations based on store analysis."""
    stats = analyze_store_languages(source_store)
    if not stats:
        return
    
    print("\n" + "=" * 80)
    print("USAGE RECOMMENDATIONS")
    print("=" * 80)
    
    if len(stats['languages']) > 1:
        print("üéØ MULTILINGUAL STORE DETECTED")
        print("\nüìà Performance Optimization Strategy:")
        print("   1. Create language-specific stores (RECOMMENDED)")
        print("   2. Query only the relevant language store")
        print("   3. Use optimized defaults (max_files=5, max_tokens=2048)")
        
        print(f"\nüíª Example Usage:")
        print("# Instead of:")
        print(f'response = manager.search_and_generate("Question?", "{source_store}")')
        print("# Use:")
        print(f'response = manager.search_and_generate("Question?", "{source_store}-english")')
        
        # Calculate expected improvement
        english_info = stats['languages'].get('english', {'size_mb': stats['total_size_mb']})
        if english_info:
            improvement = ((stats['total_size_mb'] - english_info['size_mb']) / stats['total_size_mb']) * 100
            print(f"\nüìä Expected Performance:")
            print(f"   Current: {stats['total_size_mb']:.1f} MB processed per query")
            print(f"   With English-only: {english_info['size_mb']:.1f} MB per query")
            print(f"   Improvement: {improvement:.1f}% less data = ~{100/(100-improvement if improvement != 100 else 1):.1f}x faster")
    
    else:
        print("‚úÖ SINGLE LANGUAGE STORE")
        print("\nüìà Performance Optimization Strategy:")
        print("   1. Use file limiting (max_files=3-5)")
        print("   2. Set response limits (max_tokens=1024-2048)")
        print("   3. Consider file size ranking (implemented)")
        
        print(f"\nüíª Optimized Usage:")
        print(f'response = manager.search_and_generate(')
        print(f'    "Your question?",')
        print(f'    "{source_store}",')
        print(f'    max_files=3,  # Process only 3 smallest files')
        print(f'    max_tokens=1024  # Limit response length')
        print(f')')


def main():
    """Main function for store organization."""
    print("üîß STORE ORGANIZATION UTILITY")
    print("Separate multilingual content for maximum performance")
    
    # Use the test store
    source_store = "nursing-knowledge"
    
    print(f"\nüîç Analyzing store: {source_store}")
    
    # Analyze the store
    stats = analyze_store_languages(source_store)
    if not stats:
        print(f"‚ùå Store '{source_store}' not found.")
        print("üí° Please run tests first to create the test store.")
        return
    
    # Show what would be created (dry run)
    create_language_specific_stores(source_store, dry_run=True)
    
    # Provide recommendations
    recommend_usage(source_store)
    
    # Offer to actually create stores
    print(f"\n" + "=" * 80)
    print("NEXT STEPS")
    print("=" * 80)
    print("1. Review the analysis above")
    print("2. If you want to create language-specific stores:")
    print("   Run: create_language_specific_stores('nursing-knowledge', dry_run=False)")
    print("3. Use the optimized SearchManager with new defaults")
    print("4. Test performance with quick_performance_test.py")


if __name__ == "__main__":
    main()